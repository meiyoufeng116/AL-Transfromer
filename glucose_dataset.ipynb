{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import codecs\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "def merge_glucose_data(path, path1):\n",
    "    # 列表最后为空字符串\n",
    "    data = codecs.open(path,'r').read().split('\\n')[1:-1]\n",
    "    data1 = codecs.open(path1,'r').read().split('\\n')[1:-1]\n",
    "    # key为每一个病人的id，value为一个时间戳列表和一个剂量列表\n",
    "    dictionary_glucose = {}  #{'id':[[t0,t1,t2...],[v0,v1,v2...]]}\n",
    "    # 每一行数据\n",
    "    for i, content in enumerate(data):\n",
    "\n",
    "        #try:\n",
    "        content = content.split(\",\")\n",
    "        # 3-145834-211552\n",
    "        id = content[0].strip() + '-' + content[1].strip() + '-' + content[2].strip()\n",
    "        # 以15分钟为粒度\n",
    "        t = time.mktime(time.strptime(content[3], \"%Y-%m-%d %H:%M:%S\")) / 900\n",
    "        # 使用的剂量\n",
    "        v = 0 if content[4] == '' else float(content[4])\n",
    "\n",
    "        # 此id不是第一次出现\n",
    "        if id in dictionary_glucose:\n",
    "            # 时间戳\n",
    "            dictionary_glucose[id][0].append(t)\n",
    "            # 观测量\n",
    "            dictionary_glucose[id][1].append(v)\n",
    "        else:\n",
    "            dictionary_glucose[id] = [[t], [v]]\n",
    "\n",
    "    for i, content in enumerate(data1):\n",
    "\n",
    "        content = content.split(',')\n",
    "        id = content[0] + '-' + content[1] + '-' + content[2]\n",
    "        t = time.mktime(time.strptime(content[3], \"%Y-%m-%d %H:%M:%S\")) / 900\n",
    "        v = float(content[4]) if content[4] != '' else 0\n",
    "\n",
    "        if id in dictionary_glucose:\n",
    "            dictionary_glucose[id][0].append(t)\n",
    "            dictionary_glucose[id][1].append(v)\n",
    "        else:\n",
    "            dictionary_glucose[id] = [[t],[v]]\n",
    "\n",
    "    dictionary_glucose_sorted = {}\n",
    "    for id_name in dictionary_glucose:\n",
    "        index = np.argsort(dictionary_glucose[id_name][0])\n",
    "        # 按时间戳排序\n",
    "        dictionary_glucose_sorted[id_name] = [[dictionary_glucose[id_name][0][i] for i in index], [dictionary_glucose[id_name][1][i] for i in index]]\n",
    "    torch.save(dictionary_glucose_sorted, 'datasets/dictionary_glucose_sorted.pt')\n",
    "    # save_dataset(dictionary_glucose_sorted, 'dataset/dictionary_glucose_sorted.pkl')\n",
    "    return dictionary_glucose_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def readin_insulin(path):\n",
    "    data = codecs.open(path,'r').read().split('\\n')[1:-1]\n",
    "    dictionary_insulin = {}  #{'id':[[t0,t1,t2...],[v0,v1,v2...]]}\n",
    "    for i, content in enumerate(data):\n",
    "        #try:\n",
    "        content = content.split(',')\n",
    "        id = content[0].strip() + '-' + content[1].strip() + '-' + content[2].strip()\n",
    "        st = time.mktime(time.strptime(content[4],\"%Y-%m-%d %H:%M:%S\")) / 900\n",
    "        et = time.mktime(time.strptime(content[5],\"%Y-%m-%d %H:%M:%S\")) / 900\n",
    "        # v = float(content[6]) if content[6] != '' else 0\n",
    "        v1 = float(content[6]) if content[6] != '' else 0\n",
    "        v2 = float(content[8]) if content[8] != '' else 0\n",
    "\n",
    "        if v2 == 0:\n",
    "            if id in dictionary_insulin:\n",
    "                dictionary_insulin[id][0].append(st)\n",
    "                dictionary_insulin[id][1].append(v1)\n",
    "                dictionary_insulin[id][2].append(0)\n",
    "            else:\n",
    "                dictionary_insulin[id] = [[st], [v1], [0]]\n",
    "        else:\n",
    "            # 向上取整\n",
    "            period = math.ceil(et - st)\n",
    "            if id in dictionary_insulin:\n",
    "                dictionary_insulin[id][0] += [st + i for i in range(period)]\n",
    "                dictionary_insulin[id][1] += [0 for _ in range(period)]\n",
    "                dictionary_insulin[id][2] += [v1 / period for _ in range(period)]\n",
    "            else:\n",
    "                dictionary_insulin[id] = [[st + i for i in range(period)], [0 for _ in range(period)], [v1 / period for _ in range(period)]]\n",
    "        # if round(et - st) < 1:\n",
    "        #     if id in dictionary_insulin:\n",
    "        #         dictionary_insulin[id][0].append(st)\n",
    "        #         dictionary_insulin[id][1].append(v)\n",
    "        #         dictionary_insulin[id][2].append(0)\n",
    "        #     else:\n",
    "        #         dictionary_insulin[id] = [[st],[v],[0]]\n",
    "        # else:\n",
    "        #     period = round(et - st)\n",
    "        #     # TODO\n",
    "        #     if id in dictionary_insulin:\n",
    "        #         dictionary_insulin[id][0] += [st + i for i in range(period)]\n",
    "        #         dictionary_insulin[id][1] += [0 for _ in range(period)]\n",
    "        #         dictionary_insulin[id][2] += [v / period for _ in range(period)]\n",
    "        #     else:\n",
    "        #         dictionary_insulin[id] = [[st + i for i in range(period)], [0 for _ in range(period)], [v / period for _ in range(period)]]\n",
    "    dictionary_insulin_sorted = {}\n",
    "\n",
    "    for id_name in dictionary_insulin:\n",
    "\n",
    "        # 根据起始时间排序\n",
    "        index = np.argsort(dictionary_insulin[id_name][0])\n",
    "        dictionary_insulin_sorted[id_name]=[[dictionary_insulin[id_name][0][i] for i in index], [dictionary_insulin[id_name][1][i] for i in index], [dictionary_insulin[id_name][2][i] for i in index]]\n",
    "        #print('dictionary_insulin_sorted: '+str(dictionary_insulin_sorted[n]))\n",
    "        #print(eafioj)\n",
    "    # save_dataset(dictionary_insulin_sorted, 'dataset/dictionary_insulin_sorted.pkl')\n",
    "    torch.save(dictionary_insulin_sorted, \"datasets/dictionary_insulin_sorted.pt\")\n",
    "    return dictionary_insulin_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def merge_glucose_insulin(dictionary_glucose, dictionary_insulin): #{'id':[[t0,t1,t2...],[v0,v1,v2...]]}\n",
    "    samples = {}\n",
    "    for id_name in dictionary_insulin:\n",
    "        if id_name in dictionary_glucose:\n",
    "            min_time = dictionary_glucose[id_name][0][0]\n",
    "            max_time = max(dictionary_insulin[id_name][0][-1], dictionary_glucose[id_name][0][-1])\n",
    "\n",
    "            # max_time = dictionary_glucose[id_name][0][-1]\n",
    "            # TODO\n",
    "            period = math.ceil(max_time - min_time)\n",
    "            period = period + 1 if math.ceil(period) == math.floor(period) else math.ceil(period)\n",
    "            # period = round(max_time - min_time)\n",
    "            #d = [0 for i in range(period+1)]\n",
    "            r = [0 for _ in range(period)]\n",
    "            t1 = [0 for _ in range(period)]\n",
    "            t2 = [0 for _ in range(period)]\n",
    "\n",
    "            count_r = [0 for _ in range(period)]\n",
    "            count_t1 = [0 for _ in range(period)]\n",
    "            count_t2 = [0 for _ in range(period)]\n",
    "            # TODO\n",
    "            for i, timestep in enumerate(dictionary_glucose[id_name][0]):\n",
    "\n",
    "                r[math.floor(timestep - min_time)] += dictionary_glucose[id_name][1][i]\n",
    "                count_r[math.floor(timestep - min_time)] += 1\n",
    "            for i, timestep in enumerate(dictionary_insulin[id_name][0]):\n",
    "                if timestep-min_time < 0 or timestep-max_time > -1:\n",
    "                    continue\n",
    "                if dictionary_insulin[id_name][1][i] != 0:\n",
    "                    count_t1[math.floor(timestep - min_time)] += 1\n",
    "                    t1[math.floor(timestep - min_time)] += dictionary_insulin[id_name][1][i]\n",
    "                else:\n",
    "                    count_t2[math.floor(timestep - min_time)] += 1\n",
    "                    t2[math.floor(timestep - min_time)] += dictionary_insulin[id_name][2][i]\n",
    "            for idx, cnt in enumerate(count_r):\n",
    "                if cnt > 1:\n",
    "                    r[idx] /= count_r[idx]\n",
    "            for idx, cnt in enumerate(count_t1):\n",
    "                if cnt > 1:\n",
    "                    t1[idx] /= count_t1[idx]\n",
    "            for idx, cnt in enumerate(count_t2):\n",
    "                if cnt > 1:\n",
    "                    t2[idx] /= count_t2[idx]\n",
    "\n",
    "            samples[id_name] = [r, t1, t2]\n",
    "    torch.save(samples, \"datasets/samples.pt\")\n",
    "    # save_dataset(samples, 'dataset/samples.pkl')\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def up_sample(r, t1, t2, up = 2):\n",
    "    if up < 1:\n",
    "        up = 1\n",
    "    length = int(len(r) / up)\n",
    "    r_new = []\n",
    "    t1_new = []\n",
    "    t2_new = []\n",
    "    r_carryon = []\n",
    "    current = 0\n",
    "    for i in r:\n",
    "        # 缺失值填补\n",
    "        if i == 0:\n",
    "            r_carryon.append(current)\n",
    "        else:\n",
    "            r_carryon.append(i)\n",
    "            current = i\n",
    "\n",
    "    for i in range(length):\n",
    "        # 当前窗口内的平均值\n",
    "        r_new.append(np.mean(r_carryon[up * i : up * i + up]))\n",
    "        t1_new.append(np.mean(t1[up * i : up * i + up]))\n",
    "        t2_new.append(np.mean(t2[up * i : up * i + up]))\n",
    "    return r_new, t1_new, t2_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path = \"datasets/fingerstick_glucose_icu.csv\"\n",
    "path1 = \"datasets/glucose_icu.csv\"\n",
    "dictionary_glucose_sorted = merge_glucose_data(path, path1)\n",
    "path = 'datasets/insulin_inputeventsmv_icu.csv'\n",
    "dictionary_insulin_sorted = readin_insulin(path)\n",
    "samples = merge_glucose_insulin(dictionary_glucose_sorted, dictionary_insulin_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def standardization(data):\n",
    "    mu = data.mean()\n",
    "    sigma = data.std()\n",
    "    return (data - mu) / sigma\n",
    "\n",
    "def data_norm(data): # [count, 3, length]\n",
    "    samples = data.permute(1, 0, 2)  # [3, count, length]\n",
    "    for i, sample in enumerate(samples):\n",
    "        # TODO\n",
    "        if i == len(samples) - 2:\n",
    "            break\n",
    "        samples[i] = standardization(sample) #sample_norm(sample, t)\n",
    "    return samples.permute(1, 0, 2)  # list tensor tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples count: 11927\n",
      "new samples for: 50\n",
      "2307\n"
     ]
    }
   ],
   "source": [
    "samples = torch.load('datasets/samples.pt')\n",
    "samples_new = []\n",
    "mask = []\n",
    "print('samples count: ' + str(len(samples)))\n",
    "window = [50]\n",
    "\n",
    "for w in window:\n",
    "    for id_name in samples:\n",
    "\n",
    "        r, t1, t2 = samples[id_name]\n",
    "        if int(len(r) / 50) < 4:\n",
    "            r, t1, t2 = up_sample(r, t1, t2, up = int(len(r) / 50))\n",
    "        else:\n",
    "            r, t1, t2 = up_sample(r, t1, t2, up = 4)\n",
    "\n",
    "        # for i in range(len(r) - w - 1):\n",
    "        # 滑动窗口 数据增强\n",
    "        for i in range(len(r) - w + 1):\n",
    "            # 统计缺失值的数量\n",
    "            if t1[i:i + w][-20:].count(0) + t2[i:i + w][-20:].count(0) < 36 and t1[i:i + w][:20].count(0) + t2[i:i + w][:20].count(0) < 36 and t1[i:i + w][20:30].count(0) + t2[i:i + w][20:30].count(0) < 19:\n",
    "                samples_new.append([r[i:i + w], t1[i:i + w], t2[i:i + w]])\n",
    "                #print(samples_new[n])\n",
    "                break\n",
    "    print('new samples for: ' + str(w))\n",
    "    print(len(samples_new))\n",
    "samples_new = torch.FloatTensor(samples_new)\n",
    "# mask = (samples_new > 0).mul_(1)\n",
    "mask = samples_new > 0\n",
    "samples_new = data_norm(samples_new)\n",
    "# save_dataset((samples_new,mask), 'dataset/dataset.pkl')\n",
    "torch.save((samples_new, mask), 'datasets/glucose_dataset.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2307, 3, 50])\n",
      "torch.Size([2307, 3, 50])\n"
     ]
    }
   ],
   "source": [
    "s1, s2 = torch.load('datasets/glucose_dataset.pt')\n",
    "print(s2.shape)\n",
    "print(s1.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
