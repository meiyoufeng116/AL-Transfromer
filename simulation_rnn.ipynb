{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 123\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "# torch.use_deterministic_algorithms(True)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import T\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tools.utils import EarlyStopping\n",
    "from tools.training_tools import test\n",
    "from tools.metrics import RMSE\n",
    "from tools.evaluate_tools import evaluate, evaluate_adrnn_cnn, \\\n",
    "    evaluate_adrnn_cnn_multilabel, evaluate_separate_lstm, evaluate_simulate,evaluate_simu_t, evaluate_stacked_lstm, evaluate_flat_lstm,evaluate_timesetps\n",
    "from tools.draw_lines import draw_lines\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "from ast import Try\n",
    "from cProfile import label\n",
    "import codecs\n",
    "import imp\n",
    "import os\n",
    "from turtle import color\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from nets.transformer import StackedTransformer,Transformer\n",
    "from tools.training_tools import test_informer, train_informer, train_stacked_lstm_cnn,test\n",
    "from tools.simulation import simulation, simulation_transformer\n",
    "from data.data_process import dataset_split, dataset_split_h\n",
    "from data.sepsis_dataset import (SepsisDataset, TestDataset, TrainDataset,\n",
    "                                 VaildDataset)\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': 64,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 0 \n",
    "          }\n",
    "\n",
    "dataset, mask = torch.load('./datasets/normalized_dataset_new.pt')\n",
    "train_data, train_mask, valid_data, valid_mask, test_data, test_mask = dataset_split_h(\n",
    "    dataset, mask)  # b t input\n",
    "\n",
    "train_dataset = TrainDataset(train_data, train_mask)\n",
    "vaild_dataset = VaildDataset(valid_data, valid_mask)\n",
    "test_dataset = TestDataset(test_data, test_mask)\n",
    "\n",
    "train_iterator= DataLoader(train_dataset,**params)\n",
    "vaild_iterator=DataLoader(vaild_dataset,**params)\n",
    "test_iterator=DataLoader(test_dataset,**params)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self,hidden_size=64, num_layers=2, dropout=0.2,input_size=49):\n",
    "        super(GRU, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.input_size = input_size\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=input_size,\n",
    "            hidden_size=self.hidden_size,     # rnn hidden unit\n",
    "            num_layers=self.num_layers,       # number of rnn layer\n",
    "            dropout=self.dropout,\n",
    "            batch_first=True,   # input & output will has batch size as 1s dimension. e.g. (batch, time_step, input_size)\n",
    "        )\n",
    "        self.drop_layer = nn.Dropout(p=self.dropout)\n",
    "        self.out = nn.Linear(self.hidden_size, input_size)\n",
    "\n",
    "    def forward(self, x, h_state=None, is_train=True, gen_length=None,bias=None):\n",
    "        # x (batch, time_step, input_size)\n",
    "        # h_state (n_layers, batch, hidden_size)\n",
    "        # r_out (batch, time_step, hidden_size)\n",
    "        start=12\n",
    "        batch = x.shape[0]\n",
    "        r_out, h_state = self.rnn(x, h_state)\n",
    "        #return r_out, h_state\n",
    "        r_out = self.drop_layer(r_out)\n",
    "        r_out = self.out(r_out) #-> b t inputsize\n",
    "        if is_train==False:\n",
    "            r_output = torch.zeros(gen_length, batch, self.input_size).cuda()  #   t b input_size\n",
    "            r_out = x.permute(1,0,2)[start-1] #->  b hidden_size\n",
    "            r_output[:start-1,:,:] = x.permute(1,0,2)[:start-1,:,:]\n",
    "            r_out = r_out.view(batch, 1, -1) #->  b 1 hidden_size\n",
    "            for i in range(start-1,gen_length-1):\n",
    "                r_out, h_state = self.rnn(r_out, h_state) #r_out  b 1 hidden_size\n",
    "                r_out = self.drop_layer(r_out)\n",
    "                r_out = self.out(r_out) #-> b t inputsize\n",
    "                if bias !=None:\n",
    "                    r_out[:,:,:47] = r_out[:,:,:47] +bias[:,i-(start-1):i-(start-2),:]\n",
    "                r_output[i+1]= r_out.permute(1,0,2)[0]\n",
    "\n",
    "            return r_output.permute(1,0,2), h_state\n",
    "        return r_out, h_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self,hidden_size=64, num_layers=2, dropout=0.2,input_size=49):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.input_size = input_size\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=input_size,\n",
    "            hidden_size=self.hidden_size,     # rnn hidden unit\n",
    "            num_layers=self.num_layers,       # number of rnn layer\n",
    "            dropout=self.dropout,\n",
    "            batch_first=True,   # input & output will has batch size as 1s dimension. e.g. (batch, time_step, input_size)\n",
    "        )\n",
    "        self.drop_layer = nn.Dropout(p=self.dropout)\n",
    "        self.out = nn.Linear(self.hidden_size, input_size)\n",
    "\n",
    "    def forward(self, x, h_state=None, is_train=True, gen_length=None,bias=None):\n",
    "        # x (batch, time_step, input_size)\n",
    "        # h_state (n_layers, batch, hidden_size)\n",
    "        # r_out (batch, time_step, hidden_size)\n",
    "        batch = x.shape[0]\n",
    "        start=12\n",
    "\n",
    "        if is_train==False:\n",
    "            r_output = torch.zeros(gen_length, batch, self.input_size).cuda()  #   t b input_size\n",
    "            r_out = x.permute(1,0,2)[start-1] #->  b hidden_size\n",
    "            r_output[:start-1,:,:] = x.permute(1,0,2)[:start-1,:,:]\n",
    "            r_out = r_out.view(batch, 1, -1) #->  b 1 hidden_size\n",
    "            for i in range(start-1,gen_length-1):\n",
    "                r_out, h_state = self.rnn(r_out, h_state) #r_out  b 1 hidden_size\n",
    "                r_out = self.drop_layer(r_out)\n",
    "                r_out = self.out(r_out) #-> b t inputsize\n",
    "                if bias !=None:\n",
    "                    r_out[:,:,:47] = r_out[:,:,:47] +bias[:,i-(start-1):i-(start-2),:]\n",
    "                r_output[i+1]= r_out.permute(1,0,2)[0]\n",
    "            return r_output.permute(1,0,2), h_state\n",
    "        r_out, h_state = self.rnn(x, h_state)\n",
    "        #return r_out, h_state\n",
    "        r_out = self.drop_layer(r_out)\n",
    "        r_out = self.out(r_out) #-> b t inputsize        \n",
    "        return r_out, h_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self,hidden_size=64, num_layers=2, dropout=0.2,input_size=49):\n",
    "        super(LSTM, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.input_size = input_size\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=self.hidden_size,     # rnn hidden unit\n",
    "            num_layers=self.num_layers,       # number of rnn layer\n",
    "            dropout=self.dropout,\n",
    "            batch_first=True,   # input & output will has batch size as 1s dimension. e.g. (batch, time_step, input_size)\n",
    "        )\n",
    "        self.drop_layer = nn.Dropout(p=self.dropout)\n",
    "        self.out = nn.Linear(self.hidden_size, input_size)\n",
    "\n",
    "    def forward(self, x, h_state=None, is_train=True, gen_length=None,bias=None):\n",
    "        # x (batch, time_step, input_size)\n",
    "        # h_state (n_layers, batch, hidden_size)\n",
    "        # r_out (batch, time_step, hidden_size)\n",
    "        batch = x.shape[0]\n",
    "        start=12\n",
    "        if is_train==False:\n",
    "            r_output = torch.zeros(gen_length, batch, self.input_size).cuda()  #   t b input_size\n",
    "            r_out = x.permute(1,0,2)[start-1] #->  b hidden_size\n",
    "            r_output[:start-1,:,:] = x.permute(1,0,2)[:start-1,:,:]\n",
    "            r_out = r_out.view(batch, 1, -1) #->  b 1 hidden_size\n",
    "            for i in range(start-1,gen_length-1):\n",
    "                r_out, h_state = self.rnn(r_out, h_state) #r_out  b 1 hidden_size\n",
    "                r_out = self.drop_layer(r_out)\n",
    "                r_out = self.out(r_out) #-> b t inputsize\n",
    "                if bias !=None:\n",
    "                    r_out[:,:,:47] = r_out[:,:,:47] +bias[:,i-(start-1):i-(start-2),:]\n",
    "                r_output[i+1]= r_out.permute(1,0,2)[0]\n",
    "\n",
    "            return r_output.permute(1,0,2), h_state\n",
    "        r_out, h_state = self.rnn(x, h_state)\n",
    "        #return r_out, h_state\n",
    "        r_out = self.drop_layer(r_out)\n",
    "        r_out = self.out(r_out) #-> b t inputsize        \n",
    "        \n",
    "        return r_out, h_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM2(nn.Module):\n",
    "    def __init__(self,hidden_size=64, num_layers=2, dropout=0.2,input_size=47):\n",
    "        super(LSTM2, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.input_size = input_size\n",
    "        self.rnn1 = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=self.hidden_size,     # rnn hidden unit\n",
    "            num_layers=self.num_layers,       # number of rnn layer\n",
    "            dropout=self.dropout,\n",
    "            batch_first=True,   # input & output will has batch size as 1s dimension. e.g. (batch, time_step, input_size)\n",
    "        )\n",
    "        self.rnn2 = nn.LSTM(\n",
    "            input_size=47,\n",
    "            hidden_size=self.hidden_size,     # rnn hidden unit\n",
    "            num_layers=self.num_layers,       # number of rnn layer\n",
    "            dropout=self.dropout,\n",
    "            batch_first=True,   # input & output will has batch size as 1s dimension. e.g. (batch, time_step, input_size)\n",
    "        )\n",
    "        self.drop_layer = nn.Dropout(p=self.dropout)\n",
    "        self.drop_layer2 = nn.Dropout(p=self.dropout)\n",
    "        self.out = nn.Linear(self.hidden_size, 47)\n",
    "        self.out2 = nn.Linear(self.hidden_size, 2)\n",
    "\n",
    "    def forward(self, x, h_state=None,t_state=None, is_train=True, gen_length=None,bias=None):\n",
    "        # x (batch, time_step, input_size)\n",
    "        # h_state (n_layers, batch, hidden_size)\n",
    "        # r_out (batch, time_step, hidden_size)\n",
    "        batch = x.shape[0]\n",
    "        gen_length=24\n",
    "        x=x[:,0:gen_length,:]\n",
    "        if is_train==False:\n",
    "            for i in range(gen_length):\n",
    "                Input=x[:,i:i+gen_length,:]\n",
    "                r_out, h_state = self.rnn1(Input, h_state)\n",
    "                #return r_out, h_state\n",
    "                r_out = self.drop_layer(r_out)\n",
    "                r_out = self.out(r_out) #-> b t inputsize\n",
    "                t_out, t_state = self.rnn2(r_out[:,-1:,:], t_state)\n",
    "                t_out = self.drop_layer2(t_out)\n",
    "                t_out = self.out2(t_out)\n",
    "                \n",
    "                B_out=torch.cat((r_out[:,-1:,:],t_out[:,-1:,:]),dim=2)\n",
    "                if bias!=None:\n",
    "                    B_out[:,:,:47]=B_out[:,:,:47]+bias[:,i:i+1,:]\n",
    "                x=torch.cat((x,B_out[:,-1:,:]),dim=1)\n",
    "                \n",
    "                    \n",
    "\n",
    "            return x[:,:,:], h_state\n",
    "        # batch = x.shape[0]\n",
    "        \n",
    "        \n",
    "        for i in range(gen_length):\n",
    "            Input=x[:,i:i+gen_length,:]\n",
    "            r_out, h_state = self.rnn1(Input, h_state)\n",
    "            #return r_out, h_state\n",
    "            r_out = self.drop_layer(r_out)\n",
    "            r_out = self.out(r_out) #-> b t inputsize\n",
    "            t_out, t_state = self.rnn2(r_out[:,-1:,:], t_state)\n",
    "            t_out = self.drop_layer2(t_out)\n",
    "            t_out = self.out2(t_out)\n",
    "            \n",
    "            B_out=torch.cat((r_out[:,-1:,:],t_out[:,-1:,:]),dim=2)\n",
    "            x=torch.cat((x,B_out[:,-1:,:]),dim=1)\n",
    "\n",
    "        return x[:,:,:], h_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_simulation_rnn(model, data_x, data_y, mask, response_size=47, treatment_size=2,bias=None):\n",
    "    \n",
    "    \n",
    "    length = data_x.shape[1]\n",
    "    middle_len=24\n",
    "    all_len=48\n",
    "    loss_mse = nn.MSELoss()\n",
    "    loss_mae = nn.L1Loss()\n",
    "\n",
    "    pred,_ = model(data_x, is_train=False, gen_length=all_len,bias=bias) #1,74,49\n",
    "\n",
    "    pred = torch.mul(pred[:,middle_len:all_len,:], mask[:,middle_len:all_len,:])\n",
    "\n",
    "    eval_mse_r = loss_mse(data_y[:, middle_len:all_len, :response_size], pred[:, :, :response_size]).item()\n",
    "    eval_mse_t = loss_mse(data_y[:, middle_len:all_len, -treatment_size:], pred[:, :, -treatment_size:]).item()\n",
    "    eval_mae_r = loss_mae(data_y[:, middle_len:all_len, :response_size], pred[:, :, :response_size]).item()\n",
    "    eval_mae_t = loss_mae(data_y[:, middle_len:all_len, -treatment_size:], pred[:, :, -treatment_size:]).item()\n",
    "    bias=(data_y[:, middle_len:all_len, :response_size]-pred[:,:, :response_size])\n",
    "    return eval_mse_r, eval_mse_t, eval_mae_r, eval_mae_t,bias,pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_simulation_rt(model_r,model_t, data_x, data_y, mask, response_size=47, treatment_size=2,bias=None):\n",
    "    \n",
    "    \n",
    "    length = data_x.shape[1]\n",
    "    all_len=48\n",
    "    loss_mse = nn.MSELoss()\n",
    "    loss_mae = nn.L1Loss()\n",
    "\n",
    "    pred_r,_ = model_r(data_x[:,:,:47], is_train=False, gen_length=all_len,bias=bias) #1,74,49\n",
    "    pred_t,_ = model_t(data_x[:,:,47:], is_train=False, gen_length=all_len) #1,74,49   \n",
    "\n",
    "    pred_r = torch.mul(pred_r[:,24:48,:], mask[:,24:48,:47])\n",
    "    pred_t = torch.mul(pred_t[:,24:48,:], mask[:,24:48,47:])\n",
    "\n",
    "    eval_mse_r = loss_mse(data_y[:, 24:all_len, :response_size], pred_r[:, :, :response_size]).item()\n",
    "    eval_mse_t = loss_mse(data_y[:, 24:all_len, -treatment_size:], pred_t[:, :, -treatment_size:]).item()\n",
    "    eval_mae_r = loss_mae(data_y[:, 24:all_len, :response_size], pred_r[:, :, :response_size]).item()\n",
    "    eval_mae_t = loss_mae(data_y[:, 24:all_len, -treatment_size:], pred_t[:, :, -treatment_size:]).item()\n",
    "    bias=(data_y[:, 24:all_len, :response_size]-pred_r[:,:, :response_size])\n",
    "    return eval_mse_r, eval_mse_t, eval_mae_r, eval_mae_t,bias,pred_r,pred_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM2(128, 1, 0).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "model_r=LSTM(128,1,0.2,47)\n",
    "model_t=LSTM(128,1,0.2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation_rt(test_iterator, vaild_iterator, model, is_mask, window, logger, model_save_path, response_size=47, treatment_size=2,\n",
    "               device=torch.device(\"cpu\")):\n",
    "    # model.load_state_dict(torch.load(\"trained_models/transformer/2022_08_09_13_30_10/model.pt\" ,map_location={'cuda:0':'cuda:0','cuda:1': 'cuda:0','cuda:2':'cuda:0','cuda:3':'cuda:0','cuda:4':'cuda:0',\n",
    "    #                                                                                                            'cuda:5':'cuda:0','cuda:6':'cuda:0','cuda:7':'cuda:0','cuda:8':'cuda:0','cuda:9':'cuda:0'}),)\n",
    "    model_r=LSTM(128,1,0.2,47)\n",
    "    model_t=LSTM(128,1,0.2,2)\n",
    "    model_r=torch.load(\"model_test/LSTM_r_t_[128, 256, 512]_[1, 2]_[0.2, 0.5]_[64, 128, 256]r.model\")\n",
    "    model_t=torch.load(\"model_test/LSTM_r_t_[128, 256, 512]_[1, 2]_[0.2, 0.5]_[64, 128, 256]t.model\")\n",
    "    \n",
    "    model_r = model_r.to(device)\n",
    "    model_t = model_t.to(device)\n",
    "\n",
    "    num_batch = 0\n",
    "    valid_mse_r = 0\n",
    "    valid_mse_t = 0\n",
    "    valid_mae_r = 0\n",
    "    valid_mae_t = 0\n",
    "\n",
    "    noise = torch.empty(1, 24, 47).to(device)\n",
    "\n",
    "    model_r = model_r.eval()\n",
    "    model_t = model_t.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for b, batch in enumerate(tqdm(vaild_iterator)):\n",
    "            num_batch += 1\n",
    "            data_x, mask = batch\n",
    "\n",
    "            data_x_r = data_x[:, :24, :response_size].to(device)\n",
    "            data_x_t = data_x[:, :24, -treatment_size:].to(device)\n",
    "            data_x = data_x.to(device)\n",
    "            mask = mask.to(device)\n",
    "            data_y = data_x[:, :24, :].to(device)\n",
    "\n",
    "            # eval_mse_r, eval_mse_t, eval_mae_r, eval_mae_t = evaluate_stacked_lstm(model, data_x_r, data_x_t, data_y, mask,\n",
    "            #                                                             is_mask,\n",
    "            #                                                             response_size, treatment_size)\n",
    "\n",
    "            eval_mse_r, eval_mse_t, eval_mae_r, eval_mae_t, bias, pred_r, pred_t = evaluate_simulation_rt(model_r,model_t, data_y, data_x, mask,\n",
    "                                                                                                     response_size, treatment_size)\n",
    "            valid_mse_r += eval_mse_r\n",
    "            valid_mse_t += eval_mse_t\n",
    "            valid_mae_r += eval_mae_r\n",
    "            valid_mae_t += eval_mae_t\n",
    "            noise = torch.cat([noise, bias], dim=0)\n",
    "        valid_mse_r /= num_batch\n",
    "        valid_mse_t /= num_batch\n",
    "        valid_mae_r /= num_batch\n",
    "        valid_mae_t /= num_batch\n",
    "        geometric_mean = np.exp(\n",
    "            np.log([valid_mse_r, valid_mse_t, valid_mae_r, valid_mae_t]).mean())\n",
    "        log_info = \"geometric_mean {} valid_mse_response {} valid_mse_treatment {} valid_mae_response {} valid_mae_treatment {}\". \\\n",
    "            format(round(geometric_mean, 5), round(valid_mse_r, 5), round(valid_mse_t, 5),\n",
    "                   round(valid_mae_r, 5), round(valid_mae_t, 5))\n",
    "\n",
    "    noise = noise[1:, :, :]\n",
    "    print(\"mean:\", str(noise.mean()), \"std:\", str(noise.std()))\n",
    "    num_batch = 0\n",
    "    valid_mse_r = 0\n",
    "    valid_mse_t = 0\n",
    "    valid_mae_r = 0\n",
    "    valid_mae_t = 0\n",
    "    pr_s = torch.empty(1, 24, 47).to(device)\n",
    "    pr = torch.empty(1, 48, 47).to(device)\n",
    "    pt = torch.empty(1, 48, 2).to(device)\n",
    "\n",
    "    model = model.eval()\n",
    "    sample_N = 100\n",
    "    channal = 11\n",
    "    test_mse_r = []\n",
    "    test_mse_t = []\n",
    "    test_mae_r = []\n",
    "    test_mae_t = []\n",
    "    TN=0\n",
    "    TP=0\n",
    "    FN=0\n",
    "    FP=0\n",
    "    pred_t_n=[]\n",
    "    t_n=[]\n",
    "    # pred_rsum=[]\n",
    "    # pred_tsum=[]\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for b, batch in enumerate(tqdm(test_iterator)):\n",
    "            pred_rsum = torch.zeros(1, 24, 47).to(device)\n",
    "            pred_tsum = torch.zeros(1, 24, 2).to(device)\n",
    "            for a in range(sample_N):\n",
    "                index = torch.LongTensor(random.sample(\n",
    "                    range(noise.size(0)), batch[0].size(0)))\n",
    "                # try:\n",
    "                bias = torch.index_select(noise, 0, index.cuda())\n",
    "                # bias= torch.normal(mean=0,std=0.6890,size=(bias.shape))\n",
    "                # except:\n",
    "                #     print(\"sample error\")\n",
    "                bias = bias.to(device)\n",
    "                num_batch += 1\n",
    "                data_x, mask = batch\n",
    "\n",
    "                data_x_r = data_x[:, :24, :response_size].to(device)\n",
    "                # data_x_r = data_x_r+bias\n",
    "                data_x_t = data_x[:, :24, -treatment_size:].to(device)\n",
    "                data_y = data_x[:,:24,:].to(device)\n",
    "                mask = mask.to(device)\n",
    "                data_x = data_x.to(device)\n",
    "\n",
    "                # eval_mse_r, eval_mse_t, eval_mae_r, eval_mae_t = evaluate_stacked_lstm(model, data_x_r, data_x_t, data_y, mask,\n",
    "                #                                                             is_mask,\n",
    "                #                                                             response_size, treatment_size)\n",
    "\n",
    "                \n",
    "                \n",
    "                #噪音实验\n",
    "                eval_mse_r, eval_mse_t, eval_mae_r, eval_mae_t, bias, pred_r, pred_t = evaluate_simulation_rt(model_r,model_t, data_y, data_x, mask,\n",
    "                                                                                                     response_size, treatment_size,bias=bias)\n",
    "                # for i in range(batch[0].size(0)):\n",
    "                #     treatment=data_x[i, 24:48, -treatment_size:].nonzero()\n",
    "                #     treatment_pred=pred_t[i,:,:].nonzero()\n",
    "                #     t_n.append( 0 if treatment.shape[0]==0 else 1)\n",
    "                #     pred_t_n.append(0 if treatment_pred.shape[0]==0 else 1)\n",
    "                #     if treatment.shape[0]==0 and treatment_pred.shape[0]==0:\n",
    "                #         TN=TN+1\n",
    "                #     if treatment.shape[0]!=0 and treatment_pred.shape[0]!=0:\n",
    "                #         TP=TP+1  \n",
    "                #     if treatment.shape[0]==0 and treatment_pred.shape[0]!=0:\n",
    "                #         FP=FP+1   \n",
    "                #     if treatment.shape[0]!=0 and treatment_pred.shape[0]==0:\n",
    "                #         FN=FN+1                                                                \n",
    "                \n",
    "                # time step的实验\n",
    "                # eval_mse_r, eval_mse_t, eval_mae_r, eval_mae_t, pred_r, pred_t = evaluate_timesetps(model, data_x_r, data_x_t, data_x, mask,\n",
    "                #                                                                                       is_mask,\n",
    "                #                                                                                       response_size, treatment_size)\n",
    "\n",
    "                pred_rsum = pred_rsum+pred_r[:,:,:]\n",
    "                pred_tsum = pred_tsum+pred_t[:,:,:]\n",
    "\n",
    "                valid_mse_r += eval_mse_r\n",
    "                valid_mse_t += eval_mse_t\n",
    "                valid_mae_r += eval_mae_r\n",
    "                valid_mae_t += eval_mae_t\n",
    "                # if b == 6:\n",
    "                #     pr_s = torch.cat([pr_s, pred_r[11:12, 24:, :]], dim=0)\n",
    "                    \n",
    "                #     orig = data_x[11, 0:48, channal]\n",
    "                # pr=torch.cat([pr,pred_r],dim=0)\n",
    "                # pt=torch.cat([pt,pred_t],dim=0)\n",
    "            pred_rsum /= sample_N\n",
    "\n",
    "            pred_tsum /= sample_N\n",
    "\n",
    "            loss_mse = nn.MSELoss()\n",
    "            loss_mae = nn.L1Loss()\n",
    "            all_len = 48\n",
    "            eval_mse_r = loss_mse(\n",
    "                data_x[:, 24:all_len, :response_size], pred_rsum[:, :, :]).item()\n",
    "            eval_mse_t = loss_mse(\n",
    "                data_x[:, 24:all_len, -treatment_size:], pred_tsum[:, :, :]).item()\n",
    "            eval_mae_r = loss_mae(\n",
    "                data_x[:, 24:all_len, :response_size], pred_rsum[:, :, :]).item()\n",
    "            eval_mae_t = loss_mae(\n",
    "                data_x[:, 24:all_len, -treatment_size:], pred_tsum[:, :, :]).item()\n",
    "            test_mse_r.append(eval_mse_r)\n",
    "            test_mse_t.append(eval_mse_t)\n",
    "            test_mae_r.append(eval_mae_r)\n",
    "            test_mae_t.append(eval_mae_t)\n",
    "            # fig=plt.figure()\n",
    "            # matplotlib.use('TkAgg')\n",
    "            # ax3 = plt.axes(projection='3d')\n",
    "            # x=np.arange(0,pr.shape[1])\n",
    "            # y=np.arange(0,pr.shape[2])\n",
    "            # Xx, Yy = np.meshgrid(x, y)\n",
    "            # Zz=data_x[1,Xx,Yy].cpu().numpy()\n",
    "            # plt.xlabel(\"Time\")\n",
    "            # plt.xlabel(\"Channel\")\n",
    "            # ax3.plot_surface(Xx,Yy,Zz,rstride = 1, cstride = 1,cmap='rainbow')\n",
    "            # plt.show()\n",
    "\n",
    "\n",
    "\n",
    "        valid_mse_r /= num_batch\n",
    "        valid_mse_t /= num_batch\n",
    "        valid_mae_r /= num_batch\n",
    "        valid_mae_t /= num_batch\n",
    "        geometric_mean = np.exp(\n",
    "            np.log([valid_mse_r, valid_mse_t, valid_mae_r, valid_mae_t]).mean())\n",
    "        log_info = \"test geometric_mean {} valid_mse_response {} valid_mse_treatment {} valid_mae_response {} valid_mae_treatment {}\". \\\n",
    "            format(round(geometric_mean, 5), round(valid_mse_r, 5), round(valid_mse_t, 5),\n",
    "                   round(valid_mae_r, 5), round(valid_mae_t, 5))\n",
    "    print(\"MEAN LOSS valid_mse_response {} valid_mse_treatment {} valid_mae_response {} valid_mae_treatment {}\".\n",
    "          format(round(np.mean(test_mse_r), 5), round(np.mean(test_mse_t), 5), round(np.mean(test_mae_r), 5), round(np.mean(test_mae_t), 5)))\n",
    "    print(\"geo_mean=\", np.exp(np.log([np.mean(test_mse_r), np.mean(\n",
    "        test_mse_t), np.mean(test_mae_r), np.mean(test_mae_t)]).mean()))\n",
    "    print(\"N=\", str(sample_N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation_RNN(test_iterator, vaild_iterator, model, is_mask, window, logger, model_save_path, response_size=47, treatment_size=2,\n",
    "               device=torch.device(\"cpu\")):\n",
    "\n",
    "    model=torch.load(\"model_test\\RNN123.model\")\n",
    "    model=torch.load(\"model_test\\LSTM_r_t_[128, 256, 512]_[1, 2]_[0.2, 0.5]_[64, 128, 256]all.model\")\n",
    "    # model.load_state_dict(torch.load(\"trained_models/transformer/2022_07_29_03_34_19/model.pt\",map_location='cuda:0'))\n",
    "    model = model.to(device)\n",
    "\n",
    "    num_batch = 0\n",
    "    valid_mse_r = 0\n",
    "    valid_mse_t = 0\n",
    "    valid_mae_r = 0\n",
    "    valid_mae_t = 0\n",
    "\n",
    "    start = 0\n",
    "    leng = 24\n",
    "    end= 48\n",
    "\n",
    "    noise = torch.empty(1, leng, 47).to(device)\n",
    "\n",
    "    model = model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for b, batch in enumerate(tqdm(vaild_iterator)):\n",
    "            num_batch += 1\n",
    "            data_x, mask = batch\n",
    "\n",
    "            data_x_r = data_x[:, :leng, :response_size].to(device)\n",
    "            data_x_t = data_x[:, :leng, -treatment_size:].to(device)\n",
    "            data_x = data_x.to(device)\n",
    "            mask = mask.to(device)\n",
    "            data_y = data_x[:, :leng, :].to(device)\n",
    "            # eval_mse_r, eval_mse_t, eval_mae_r, eval_mae_t = evaluate_stacked_lstm(model, data_x_r, data_x_t, data_y, mask,\n",
    "            #                                                             is_mask,\n",
    "            #                                                             response_size, treatment_size)\n",
    "\n",
    "            eval_mse_r, eval_mse_t, eval_mae_r, eval_mae_t, bias, pred = evaluate_simulation_rnn(model, data_y ,data_x, mask,\n",
    "                                                                                                     \n",
    "                                                                                                     response_size, treatment_size)\n",
    "            valid_mse_r += eval_mse_r\n",
    "            valid_mse_t += eval_mse_t\n",
    "            valid_mae_r += eval_mae_r\n",
    "            valid_mae_t += eval_mae_t\n",
    "            noise = torch.cat([noise, bias], dim=0)\n",
    "        valid_mse_r /= num_batch\n",
    "        valid_mse_t /= num_batch\n",
    "        valid_mae_r /= num_batch\n",
    "        valid_mae_t /= num_batch\n",
    "        geometric_mean = np.exp(\n",
    "            np.log([valid_mse_r, valid_mse_t, valid_mae_r, valid_mae_t]).mean())\n",
    "        # log_info = \"geometric_mean {} valid_mse_response {} valid_mse_treatment {} valid_mae_response {} valid_mae_treatment {}\". \\\n",
    "        #     format(round(geometric_mean, 5), round(valid_mse_r, 5), round(valid_mse_t, 5),\n",
    "        #            round(valid_mae_r, 5), round(valid_mae_t, 5))\n",
    "\n",
    "    noise = noise[1:, :, :]\n",
    "    print(\"mean:\", str(noise.mean()), \"std:\", str(noise.var()))\n",
    "    num_batch = 0\n",
    "    valid_mse_r = 0\n",
    "    valid_mse_t = 0\n",
    "    valid_mae_r = 0\n",
    "    valid_mae_t = 0\n",
    "    pr_s = torch.empty(1, leng, 47).to(device)\n",
    "    pr = torch.empty(1, end, 47).to(device)\n",
    "    pt = torch.empty(1, end, 2).to(device)\n",
    "\n",
    "    model = model.eval()\n",
    "    sample_N = 100\n",
    "    channal = 11\n",
    "    test_mse_r = []\n",
    "    test_mse_t = []\n",
    "    test_mae_r = []\n",
    "    test_mae_t = []\n",
    "    TN=0\n",
    "    TP=0\n",
    "    FN=0\n",
    "    FP=0\n",
    "    pred_t_n=[]\n",
    "    t_n=[]\n",
    "    # pred_rsum=[]\n",
    "    # pred_tsum=[]\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for b, batch in enumerate(tqdm(test_iterator)):\n",
    "            pred_rsum = torch.zeros(1, leng, 47).to(device)\n",
    "            pred_tsum = torch.zeros(1, leng, 2).to(device)\n",
    "            for a in range(sample_N):\n",
    "                index = torch.LongTensor(random.sample(\n",
    "                    range(noise.size(0)), batch[0].size(0)))\n",
    "                # try:\n",
    "                bias = torch.index_select(noise, 0, index.cuda())\n",
    "                # bias= torch.normal(mean=0,std=0.668,size=(bias.shape))  #our bias\n",
    "                # bias= torch.normal(mean=0,std=0.4528,size=(bias.shape))  #Tranformer bias\n",
    "                # bias= torch.normal(mean=0,std=1,size=(bias.shape))  #Informer bias\n",
    "                # bias= torch.normal(mean=0,std=0.8020,size=(bias.shape))  #GRU\n",
    "                # bias= torch.normal(mean=0,std=0.7803,size=(bias.shape))  #lstmRT bias\n",
    "                # except:\n",
    "                #     print(\"sample error\")\n",
    "                bias = bias.to(device)\n",
    "                num_batch += 1\n",
    "                data_x, mask = batch\n",
    "                data_x=data_x.to(device)\n",
    "                data_x_r = data_x[:, :leng, :response_size].to(device)\n",
    "                # data_x_r = data_x_r+bias\n",
    "                # data_x[:, :24, :response_size]=data_x[:, :24, :response_size]+bias\n",
    "                data_x_in=data_x[:, :leng, :]\n",
    "                data_x_t = data_x[:, :leng, -treatment_size:].to(device)\n",
    "                # data_y = data_y.to(device)\n",
    "                mask = mask.to(device)\n",
    "                # data_x = data_x.to(device)\n",
    "\n",
    "                # eval_mse_r, eval_mse_t, eval_mae_r, eval_mae_t = evaluate_stacked_lstm(model, data_x_r, data_x_t, data_y, mask,\n",
    "                #                                                             is_mask,\n",
    "                #                                                             response_size, treatment_size)\n",
    "\n",
    "                \n",
    "                \n",
    "                #噪音实验\n",
    "                eval_mse_r, eval_mse_t, eval_mae_r, eval_mae_t, _, pred = evaluate_simulation_rnn(model, data_x_in, data_x, mask,                                                                                     \n",
    "                                                                                                response_size, treatment_size,bias=bias)                # for i in range(batch[0].size(0)):\n",
    "                #     treatment=data_x[i, 24:48, -treatment_size:].nonzero()\n",
    "                #     treatment_pred=pred_t[i,:,:].nonzero()\n",
    "                #     t_n.append( 0 if treatment.shape[0]==0 else 1)\n",
    "                #     pred_t_n.append(0 if treatment_pred.shape[0]==0 else 1)\n",
    "                #     if treatment.shape[0]==0 and treatment_pred.shape[0]==0:\n",
    "                #         TN=TN+1\n",
    "                #     if treatment.shape[0]!=0 and treatment_pred.shape[0]!=0:\n",
    "                #         TP=TP+1  \n",
    "                #     if treatment.shape[0]==0 and treatment_pred.shape[0]!=0:\n",
    "                #         FP=FP+1   \n",
    "                #     if treatment.shape[0]!=0 and treatment_pred.shape[0]==0:\n",
    "                #         FN=FN+1                                                                \n",
    "                \n",
    "                # time step的实验\n",
    "                # eval_mse_r, eval_mse_t, eval_mae_r, eval_mae_t, pred_r, pred_t = evaluate_timesetps(model, data_x_r, data_x_t, data_x, mask,\n",
    "                #                                                                                       is_mask,\n",
    "                #                                                                                       response_size, treatment_size)\n",
    "\n",
    "                pred_rsum = pred_rsum+pred[:, :, :response_size]\n",
    "                pred_tsum = pred_tsum+pred[:, :, -treatment_size:]\n",
    "\n",
    "                valid_mse_r += eval_mse_r\n",
    "                valid_mse_t += eval_mse_t\n",
    "                valid_mae_r += eval_mae_r\n",
    "                valid_mae_t += eval_mae_t\n",
    "                if b == 6:\n",
    "                    pr_s = torch.cat([pr_s, pred[11:12, :leng, :47]], dim=0)\n",
    "                    \n",
    "                    orig = data_x[11, leng:end, channal]\n",
    "                # pr=torch.cat([pr,pred_r],dim=0)\n",
    "                # pt=torch.cat([pt,pred_t],dim=0)\n",
    "            pred_rsum /= sample_N\n",
    "\n",
    "            pred_tsum /= sample_N\n",
    "\n",
    "            loss_mse = nn.MSELoss()\n",
    "            loss_mae = nn.L1Loss()\n",
    "            all_len = 48\n",
    "            eval_mse_r = loss_mse(\n",
    "                data_x[:, leng:all_len, :response_size], pred_rsum[:, :, :]).item()\n",
    "            eval_mse_t = loss_mse(\n",
    "                data_x[:, leng:all_len, -treatment_size:], pred_tsum[:, :, :]).item()\n",
    "            eval_mae_r = loss_mae(\n",
    "                data_x[:, leng:all_len, :response_size], pred_rsum[:, :, :]).item()\n",
    "            eval_mae_t = loss_mae(\n",
    "                data_x[:, leng:all_len, -treatment_size:], pred_tsum[:, :, :]).item()\n",
    "            test_mse_r.append(eval_mse_r)\n",
    "            test_mse_t.append(eval_mse_t)\n",
    "            test_mae_r.append(eval_mae_r)\n",
    "            test_mae_t.append(eval_mae_t)\n",
    "            # fig=plt.figure()\n",
    "            # matplotlib.use('TkAgg')\n",
    "            # ax3 = plt.axes(projection='3d')\n",
    "            # x=np.arange(0,pr.shape[1])\n",
    "            # y=np.arange(0,pr.shape[2])\n",
    "            # Xx, Yy = np.meshgrid(x, y)\n",
    "            # Zz=data_x[1,Xx,Yy].cpu().numpy()\n",
    "            # plt.xlabel(\"Time\")\n",
    "            # plt.xlabel(\"Channel\")\n",
    "            # ax3.plot_surface(Xx,Yy,Zz,rstride = 1, cstride = 1,cmap='rainbow')\n",
    "            # plt.show()\n",
    "\n",
    "\n",
    "\n",
    "        valid_mse_r /= num_batch\n",
    "        valid_mse_t /= num_batch\n",
    "        valid_mae_r /= num_batch\n",
    "        valid_mae_t /= num_batch\n",
    "        geometric_mean = np.exp(\n",
    "            np.log([valid_mse_r, valid_mse_t, valid_mae_r, valid_mae_t]).mean())\n",
    "        log_info = \"test geometric_mean {} valid_mse_response {} valid_mse_treatment {} valid_mae_response {} valid_mae_treatment {}\". \\\n",
    "            format(round(geometric_mean, 5), round(valid_mse_r, 5), round(valid_mse_t, 5),\n",
    "                   round(valid_mae_r, 5), round(valid_mae_t, 5))\n",
    "    print(\"MEAN LOSS valid_mse_response {} valid_mse_treatment {} valid_mae_response {} valid_mae_treatment {}\".\n",
    "          format(round(np.mean(test_mse_r), 5), round(np.mean(test_mse_t), 5), round(np.mean(test_mae_r), 5), round(np.mean(test_mae_t), 5)))\n",
    "    print(\"geo_mean=\", np.exp(np.log([np.mean(test_mse_r), np.mean(\n",
    "        test_mse_t), np.mean(test_mae_r), np.mean(test_mae_t)]).mean()))\n",
    "    print(\"N=\", str(sample_N))\n",
    "    # logger.info(log_info)\n",
    "    # logger.info(\"\\n\")\n",
    "    # logger.info(\"best_geometric_mean {}\\n\".format(round(geometric_mean, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM2(\n",
       "  (rnn1): LSTM(47, 128, batch_first=True)\n",
       "  (rnn2): LSTM(47, 128, batch_first=True)\n",
       "  (drop_layer): Dropout(p=0, inplace=False)\n",
       "  (drop_layer2): Dropout(p=0, inplace=False)\n",
       "  (out): Linear(in_features=128, out_features=47, bias=True)\n",
       "  (out2): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:01<00:00, 20.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: tensor(-0.0060, device='cuda:0') std: tensor(0.5202, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:54<00:00,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN LOSS valid_mse_response 0.48337 valid_mse_treatment 0.03196 valid_mae_response 0.4304 valid_mae_treatment 0.0687\n",
      "geo_mean= 0.14619657869839497\n",
      "N= 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "simulation_RNN( test_iterator,vaild_iterator, model, True, window=12, logger=None,\n",
    "                         model_save_path=os.path.join(\"model_test\", \"rnn-model.pt\"), response_size=47, treatment_size=2, device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:00<00:00, 51.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: tensor(0.0354, device='cuda:0') std: tensor(0.7622, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:18<00:00,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN LOSS valid_mse_response 0.6699 valid_mse_treatment 0.03885 valid_mae_response 0.46961 valid_mae_treatment 0.10547\n",
      "geo_mean= 0.18948053315542857\n",
      "N= 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "simulation_RNN( test_iterator,vaild_iterator, model, True, window=12, logger=None,\n",
    "                         model_save_path=os.path.join(\"model_test\", \"rnn-model.pt\"), response_size=47, treatment_size=2, device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
